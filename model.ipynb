{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-29 05:38:24--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.212.128, 2607:f8b0:4001:c03::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.212.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 187925923 (179M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_co 100%[===================>] 179.22M   189MB/s    in 1.0s    \n",
      "\n",
      "2020-04-29 05:38:25 (189 MB/s) - ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’ saved [187925923/187925923]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/workspace/Convert model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.ipynb  ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v2_coco_2018_03_29/checkpoint\n",
      "ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.meta\n",
      "ssd_mobilenet_v2_coco_2018_03_29/pipeline.config\n",
      "ssd_mobilenet_v2_coco_2018_03_29/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\n",
      "ssd_mobilenet_v2_coco_2018_03_29/saved_model/\n",
      "ssd_mobilenet_v2_coco_2018_03_29/saved_model/variables/\n",
      "ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.index\n",
      "ssd_mobilenet_v2_coco_2018_03_29/\n",
      "ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf ssd_mobilenet_v2_coco_2018_03_29.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.ipynb                        ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
      "\u001b[0m\u001b[01;34mssd_mobilenet_v2_coco_2018_03_29\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace/Convert model/ssd_mobilenet_v2_coco_2018_03_29\n"
     ]
    }
   ],
   "source": [
    "cd ssd_mobilenet_v2_coco_2018_03_29/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/workspace/Convert model/ssd_mobilenet_v2_coco_2018_03_29'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                      model.ckpt.index  \u001b[0m\u001b[01;34msaved_model\u001b[0m/\n",
      "frozen_inference_graph.pb       model.ckpt.meta\n",
      "model.ckpt.data-00000-of-00001  pipeline.config\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/workspace/Convert model/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\n",
      "\t- Path for generated IR: \t/home/workspace/Convert model/ssd_mobilenet_v2_coco_2018_03_29/.\n",
      "\t- IR output name: \tfrozen_inference_graph\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tTrue\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \t/home/workspace/Convert model/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \t/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n",
      "Model Optimizer version: \t2019.3.0-408-gac8584cb7\n",
      "The Preprocessor block has been removed. Only nodes performing mean value subtraction and scaling (if applicable) are kept.\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/workspace/Convert model/ssd_mobilenet_v2_coco_2018_03_29/./frozen_inference_graph.xml\n",
      "[ SUCCESS ] BIN file: /home/workspace/Convert model/ssd_mobilenet_v2_coco_2018_03_29/./frozen_inference_graph.bin\n",
      "[ SUCCESS ] Total execution time: 65.48 seconds. \n"
     ]
    }
   ],
   "source": [
    "! python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py --input_model frozen_inference_graph.pb --tensorflow_object_detection_api_pipeline_config pipeline.config --reverse_input_channels --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                      frozen_inference_graph.xml      pipeline.config\n",
      "frozen_inference_graph.bin      model.ckpt.data-00000-of-00001  \u001b[0m\u001b[01;34msaved_model\u001b[0m/\n",
      "frozen_inference_graph.mapping  model.ckpt.index\n",
      "frozen_inference_graph.pb       model.ckpt.meta\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frozen_inference_graph.bin \n",
    "#frozen_inference_graph.xml are the requierd files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
